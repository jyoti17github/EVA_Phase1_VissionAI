{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fourth _Assignment_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQzoExKk_Fxa",
        "colab_type": "text"
      },
      "source": [
        "## Observation from Third network :From 3rd  network( 9925 accuracy in 40 epochs) I made a note that \n",
        "###* multiple time running networks will not help to improve acuracy as network starts overfitting.\n",
        "###Some other concepts are required to solve overfitting problem and improve training and val accuracy\n",
        "###* Parameters kept with same numbers as it made network to learn till 40 epochs to max achievable accuracy\n",
        "\n",
        "### please Note as in first network i added comments in per block , here skipping:("
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDeuFNq2CBHO",
        "colab_type": "text"
      },
      "source": [
        "##TRY in this network\n",
        "###1. Dropout\n",
        "###2. Tuning dropout parameters less to more  from top to down layers \n",
        "### Dropouts should not use in near last layers\n",
        "###3.  Gradually increase Batch size and epochs count\n",
        "\n",
        "##Improvment from Third Network : With  8332 parameters in 50 epochs achieved 9948 val accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "f6a5d172-2bfa-4370-f066-20be1ffe28c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f80e34bb128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/EBThB4Ii/EBQhB8I6v8AG8x2aarNGp8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "7be81b35-9894-4d9a-9f87-498dba73190b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "7a6ff32b-c0c4-474f-f132-5dac73d3db1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdjtGyRerlBY",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DdfqKG4riGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "55172cd0-47e6-4590-d82b-a48a80edd476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1024
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name ='FirstLayer', input_shape=(28,28,1))) # RF 3x3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu' ,name ='SecondLayer')) # RF 5x5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(14, 3, 3, activation='relu' , name ='ThirdLayer')) # RF 7x7\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # RF 14x14\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, activation='relu'))\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu' , name ='fourthThirdLayer'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu' , name ='FifthLayer'))\n",
        "model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu' , name ='SixthLayer'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu' , name ='SeventhLayer'))\n",
        "# model.add(Convolution2D(16, 3, 3, activation='relu' , name ='8Layer'))\n",
        "\n",
        "model.add(Convolution2D(10, 1))#2\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"FirstLayer\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"SecondLayer\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(14, (3, 3), activation=\"relu\", name=\"ThirdLayer\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"fourthThirdLayer\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "FirstLayer (Conv2D)          (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "SecondLayer (Conv2D)         (None, 24, 24, 12)        1092      \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 24, 24, 12)        48        \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 24, 24, 12)        0         \n",
            "_________________________________________________________________\n",
            "ThirdLayer (Conv2D)          (None, 22, 22, 14)        1526      \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 22, 22, 14)        56        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 11, 11, 14)        0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 11, 11, 14)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 9, 9, 10)          1270      \n",
            "_________________________________________________________________\n",
            "fourthThirdLayer (Conv2D)    (None, 7, 7, 12)          1092      \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 7, 7, 12)          48        \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 7, 7, 12)          0         \n",
            "_________________________________________________________________\n",
            "FifthLayer (Conv2D)          (None, 5, 5, 10)          1090      \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "SixthLayer (Conv2D)          (None, 3, 3, 10)          910       \n",
            "_________________________________________________________________\n",
            "SeventhLayer (Conv2D)        (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 1, 1, 10)          110       \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 8,332\n",
            "Trainable params: 8,216\n",
            "Non-trainable params: 116\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"FifthLayer\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"SixthLayer\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"SeventhLayer\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH7phmhr4-78",
        "colab_type": "text"
      },
      "source": [
        "## batchnormalization addition increased epochs time as see val acc is increasing so can be try if it further increased on no of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "af673d97-396f-4bde-ad6f-217c662c7b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10,validation_data=(X_test,Y_test), verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.3847 - acc: 0.8735 - val_loss: 0.0746 - val_acc: 0.9770\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 23s 376us/step - loss: 0.0993 - acc: 0.9693 - val_loss: 0.0539 - val_acc: 0.9837\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 21s 344us/step - loss: 0.0772 - acc: 0.9761 - val_loss: 0.0517 - val_acc: 0.9852\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 21s 348us/step - loss: 0.0664 - acc: 0.9798 - val_loss: 0.0437 - val_acc: 0.9862\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 20s 339us/step - loss: 0.0597 - acc: 0.9814 - val_loss: 0.0414 - val_acc: 0.9878\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 21s 358us/step - loss: 0.0554 - acc: 0.9830 - val_loss: 0.0331 - val_acc: 0.9896\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 20s 340us/step - loss: 0.0509 - acc: 0.9839 - val_loss: 0.0369 - val_acc: 0.9891\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0495 - acc: 0.9851 - val_loss: 0.0352 - val_acc: 0.9895\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 21s 353us/step - loss: 0.0451 - acc: 0.9859 - val_loss: 0.0334 - val_acc: 0.9892\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 22s 363us/step - loss: 0.0444 - acc: 0.9864 - val_loss: 0.0296 - val_acc: 0.9896\n",
            "[0.029559062588436064, 0.9896]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "d5c2c097-067f-4584-8eff-4f39af3e4e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.029559062588436064, 0.9896]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbZGNOfl5voj",
        "colab_type": "code",
        "outputId": "8776f4d8-1599-4a91-b669-7758192feb03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, nb_epoch=10,validation_data=(X_test,Y_test), verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "  640/60000 [..............................] - ETA: 16s - loss: 0.0449 - acc: 0.9828"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0339 - acc: 0.9887 - val_loss: 0.0291 - val_acc: 0.9916\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0349 - acc: 0.9888 - val_loss: 0.0363 - val_acc: 0.9887\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0345 - acc: 0.9889 - val_loss: 0.0306 - val_acc: 0.9902\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0330 - acc: 0.9895 - val_loss: 0.0262 - val_acc: 0.9919\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0339 - acc: 0.9893 - val_loss: 0.0306 - val_acc: 0.9910\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0324 - acc: 0.9896 - val_loss: 0.0269 - val_acc: 0.9916\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0317 - acc: 0.9900 - val_loss: 0.0285 - val_acc: 0.9923\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0321 - acc: 0.9901 - val_loss: 0.0262 - val_acc: 0.9920\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0325 - acc: 0.9896 - val_loss: 0.0289 - val_acc: 0.9920\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0294 - acc: 0.9908 - val_loss: 0.0258 - val_acc: 0.9917\n",
            "[0.025815005174069667, 0.9917]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVf1rP5sA6nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3GIf7Es7cad",
        "colab_type": "code",
        "outputId": "91365ab5-9552-413e-d64a-3a5e36153429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.025815005174069667, 0.9917]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT2_ya54Cnpz",
        "colab_type": "code",
        "outputId": "e3fbb2bb-f92a-4c5b-f16a-586f2d2bfdc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=128, nb_epoch=10,validation_data=(X_test,Y_test), verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " 1792/60000 [..............................] - ETA: 5s - loss: 0.0180 - acc: 0.9939"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0242 - acc: 0.9922 - val_loss: 0.0248 - val_acc: 0.9930\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0232 - acc: 0.9923 - val_loss: 0.0282 - val_acc: 0.9921\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0255 - acc: 0.9923 - val_loss: 0.0285 - val_acc: 0.9916\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0227 - acc: 0.9928 - val_loss: 0.0240 - val_acc: 0.9931\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0235 - acc: 0.9925 - val_loss: 0.0246 - val_acc: 0.9929\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0252 - acc: 0.9916 - val_loss: 0.0263 - val_acc: 0.9929\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0237 - acc: 0.9923 - val_loss: 0.0280 - val_acc: 0.9920\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0236 - acc: 0.9927 - val_loss: 0.0291 - val_acc: 0.9922\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0242 - acc: 0.9919 - val_loss: 0.0224 - val_acc: 0.9934\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0229 - acc: 0.9924 - val_loss: 0.0215 - val_acc: 0.9935\n",
            "[0.021511087236375896, 0.9935]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bO9fSPTHK9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.compile(loss='categorical_crossentropy',\n",
        "# #               optimizer=keras.optimizers.Adam(lr=0.00001),\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#              optimizer='adam',\n",
        "#              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnGRvOVDHhxt",
        "colab_type": "code",
        "outputId": "7dea2c89-024c-49c9-f90a-dbf438e62f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=256, nb_epoch=10,validation_data=(X_test,Y_test), verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " 2048/60000 [>.............................] - ETA: 3s - loss: 0.0223 - acc: 0.9912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0203 - acc: 0.9935 - val_loss: 0.0205 - val_acc: 0.9941\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0189 - acc: 0.9937 - val_loss: 0.0219 - val_acc: 0.9947\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0176 - acc: 0.9942 - val_loss: 0.0218 - val_acc: 0.9932\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0205 - acc: 0.9935 - val_loss: 0.0224 - val_acc: 0.9937\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0190 - acc: 0.9939 - val_loss: 0.0230 - val_acc: 0.9936\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0185 - acc: 0.9942 - val_loss: 0.0218 - val_acc: 0.9939\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0199 - acc: 0.9938 - val_loss: 0.0235 - val_acc: 0.9928\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0199 - acc: 0.9936 - val_loss: 0.0221 - val_acc: 0.9934\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0190 - acc: 0.9941 - val_loss: 0.0228 - val_acc: 0.9932\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0194 - acc: 0.9939 - val_loss: 0.0210 - val_acc: 0.9943\n",
            "[0.02098737295259052, 0.9943]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_RPKdlG7cFV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD6lKNOuyZ7O",
        "colab_type": "code",
        "outputId": "81ba535d-7aec-4cdc-c33c-515694f2bc7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=512, nb_epoch=10,validation_data=(X_test,Y_test), verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " 2560/60000 [>.............................] - ETA: 3s - loss: 0.0250 - acc: 0.9906"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 50us/step - loss: 0.0156 - acc: 0.9949 - val_loss: 0.0217 - val_acc: 0.9942\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0170 - acc: 0.9946 - val_loss: 0.0206 - val_acc: 0.9936\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0155 - acc: 0.9953 - val_loss: 0.0226 - val_acc: 0.9941\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0162 - acc: 0.9946 - val_loss: 0.0214 - val_acc: 0.9943\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0159 - acc: 0.9949 - val_loss: 0.0215 - val_acc: 0.9941\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0158 - acc: 0.9950 - val_loss: 0.0212 - val_acc: 0.9945\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0173 - acc: 0.9944 - val_loss: 0.0221 - val_acc: 0.9942\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0231 - val_acc: 0.9941\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.0161 - acc: 0.9946 - val_loss: 0.0216 - val_acc: 0.9937\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.0160 - acc: 0.9944 - val_loss: 0.0201 - val_acc: 0.9948\n",
            "[0.02010944785464453, 0.9948]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "fd90236f-d7cf-4109-a001-95d48e08fb90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.51205566e-12 6.75397985e-07 1.05889370e-07 4.08880078e-06\n",
            "  2.31549592e-07 1.51425283e-09 1.05805102e-16 9.99994516e-01\n",
            "  6.52628729e-10 3.38623749e-07]\n",
            " [3.94797752e-07 8.45393242e-06 9.99967456e-01 2.98632017e-07\n",
            "  1.20950710e-06 1.85855651e-08 3.16353226e-06 3.93741516e-07\n",
            "  1.85483386e-05 4.02060110e-08]\n",
            " [8.09299711e-11 9.99987960e-01 4.82156359e-08 2.95471381e-08\n",
            "  2.87236361e-07 3.93355862e-07 9.17587284e-10 1.12560774e-05\n",
            "  1.11563225e-09 5.45822232e-09]\n",
            " [9.99999404e-01 1.26883408e-13 1.82295228e-08 4.21577412e-10\n",
            "  9.45501056e-12 1.99477523e-09 5.43011311e-07 2.81010604e-10\n",
            "  4.80997180e-08 1.26287081e-09]\n",
            " [4.82932271e-13 4.40141784e-10 2.56039123e-09 4.22055755e-13\n",
            "  9.99548137e-01 8.76318740e-10 1.46488599e-10 1.66523080e-08\n",
            "  1.38350828e-07 4.51756729e-04]\n",
            " [6.03773032e-10 9.99956727e-01 2.62566402e-07 1.10552435e-07\n",
            "  8.18209060e-07 5.57711985e-07 1.29488842e-09 4.15829818e-05\n",
            "  4.73957762e-09 3.47916398e-08]\n",
            " [2.74168353e-14 1.34394440e-07 1.06766436e-08 1.34908274e-12\n",
            "  9.99355614e-01 7.84113183e-08 2.67163583e-11 5.08930043e-07\n",
            "  1.92532525e-06 6.41804188e-04]\n",
            " [1.22533650e-14 2.32624944e-12 7.14839819e-12 6.91576219e-09\n",
            "  1.41198370e-06 3.17891957e-09 5.54300087e-19 2.50822718e-09\n",
            "  6.83931560e-08 9.99998450e-01]\n",
            " [1.17919832e-07 1.64920107e-12 8.63555646e-13 3.94937700e-07\n",
            "  6.00712568e-13 9.98756766e-01 1.23296177e-03 1.39572584e-17\n",
            "  7.86012242e-06 1.88377419e-06]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'FirstLayer'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}