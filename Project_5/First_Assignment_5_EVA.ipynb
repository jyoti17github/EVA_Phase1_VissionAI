{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First_Assignment_5_EVA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDeuFNq2CBHO",
        "colab_type": "text"
      },
      "source": [
        "### Image Normalization  Val accuracy achieved 0.9939 over 40 epochs\n",
        "### Used my own network of Assignmnet 4 ( 8372 parameters with 9948 accuracy)\n",
        "### Observation - accuracy decreased  by less than 1 percent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "c7f07d8d-e6b7-4f0b-f933-4765144ee012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets and APPLy Image normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-jwdi7iejmv",
        "colab_type": "code",
        "outputId": "157c8790-2c82-4daf-e78b-1b559aff5caa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# example of standardizing a image dataset\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "# image normalization using Image generator\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "6846a070-c35e-4fd9-c151-c3fe83deefd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "trainy[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "trainy = np_utils.to_categorical(trainy, 10)\n",
        "testy = np_utils.to_categorical(testy, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "0063ddd6-1280-464a-adfe-651b73a46207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "trainy[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiX_1KmDzMZe",
        "colab_type": "text"
      },
      "source": [
        "### Applied standard image normalization.\n",
        "observation - pixel wise normalization led to overfitting and val accuracy dropped drastically\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "8550a3e2-d4a7-4b85-a3a1-69a9dfbfa81d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1124
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name ='FirstLayer', input_shape=(28,28,1))) # RF 3x3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu' ,name ='SecondLayer')) # RF 5x5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(14, 3, 3, activation='relu' , name ='ThirdLayer')) # RF 7x7\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # RF 14x14\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, activation='relu'))\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu' , name ='fourthThirdLayer'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu' , name ='FifthLayer'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu' , name ='SixthLayer'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu' , name ='SeventhLayer'))\n",
        "\n",
        "model.add(Convolution2D(10, 1))#2\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"FirstLayer\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"SecondLayer\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(14, (3, 3), activation=\"relu\", name=\"ThirdLayer\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"fourthThirdLayer\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"FifthLayer\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"SixthLayer\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"SeventhLayer\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "FirstLayer (Conv2D)          (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "SecondLayer (Conv2D)         (None, 24, 24, 12)        1092      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 12)        48        \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 12)        0         \n",
            "_________________________________________________________________\n",
            "ThirdLayer (Conv2D)          (None, 22, 22, 14)        1526      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 14)        56        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 14)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 11, 11, 14)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 9, 9, 10)          1270      \n",
            "_________________________________________________________________\n",
            "fourthThirdLayer (Conv2D)    (None, 7, 7, 12)          1092      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 7, 7, 12)          48        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 7, 7, 12)          0         \n",
            "_________________________________________________________________\n",
            "FifthLayer (Conv2D)          (None, 5, 5, 10)          1090      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "SixthLayer (Conv2D)          (None, 3, 3, 10)          910       \n",
            "_________________________________________________________________\n",
            "SeventhLayer (Conv2D)        (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 1, 1, 10)          110       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 8,332\n",
            "Trainable params: 8,216\n",
            "Non-trainable params: 116\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er_4VUuSX8hw",
        "colab_type": "text"
      },
      "source": [
        "used LR scheduler to reach local minimas while learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UW-SvjCsmSD",
        "colab_type": "code",
        "outputId": "13f5948f-7603-411e-ccb1-e2e2ad1259d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2847
        }
      },
      "source": [
        "epochs = 40\n",
        "\n",
        "model.fit_generator(\n",
        "        datagen.flow(trainX, trainy, batch_size =128),\n",
        "        steps_per_epoch= len(trainX)/128, \n",
        "        epochs = epochs , \n",
        "        validation_data=(testX, testy),\n",
        "        callbacks=[LearningRateScheduler(scheduler, verbose=1)],\n",
        "        verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:699: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:707: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "469/468 [==============================] - 10s 22ms/step - loss: 0.3835 - acc: 0.8775 - val_loss: 0.0874 - val_acc: 0.9730\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0948 - acc: 0.9716 - val_loss: 0.0479 - val_acc: 0.9853\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0696 - acc: 0.9786 - val_loss: 0.0502 - val_acc: 0.9844\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0607 - acc: 0.9812 - val_loss: 0.0426 - val_acc: 0.9866\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0518 - acc: 0.9842 - val_loss: 0.0355 - val_acc: 0.9888\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0484 - acc: 0.9850 - val_loss: 0.0349 - val_acc: 0.9893\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0440 - acc: 0.9865 - val_loss: 0.0464 - val_acc: 0.9863\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0420 - acc: 0.9871 - val_loss: 0.0307 - val_acc: 0.9911\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0389 - acc: 0.9878 - val_loss: 0.0271 - val_acc: 0.9924\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0363 - acc: 0.9887 - val_loss: 0.0321 - val_acc: 0.9904\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0352 - acc: 0.9886 - val_loss: 0.0288 - val_acc: 0.9909\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0340 - acc: 0.9892 - val_loss: 0.0263 - val_acc: 0.9918\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0331 - acc: 0.9896 - val_loss: 0.0295 - val_acc: 0.9907\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0314 - acc: 0.9904 - val_loss: 0.0271 - val_acc: 0.9924\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0301 - acc: 0.9908 - val_loss: 0.0269 - val_acc: 0.9923\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0297 - acc: 0.9906 - val_loss: 0.0273 - val_acc: 0.9919\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0288 - acc: 0.9909 - val_loss: 0.0264 - val_acc: 0.9920\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0291 - acc: 0.9908 - val_loss: 0.0270 - val_acc: 0.9923\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0289 - acc: 0.9911 - val_loss: 0.0273 - val_acc: 0.9917\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0283 - acc: 0.9911 - val_loss: 0.0274 - val_acc: 0.9925\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0275 - acc: 0.9910 - val_loss: 0.0250 - val_acc: 0.9928\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0265 - acc: 0.9914 - val_loss: 0.0242 - val_acc: 0.9929\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0251 - acc: 0.9921 - val_loss: 0.0232 - val_acc: 0.9929\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0255 - acc: 0.9919 - val_loss: 0.0231 - val_acc: 0.9932\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0258 - acc: 0.9919 - val_loss: 0.0235 - val_acc: 0.9926\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0257 - acc: 0.9921 - val_loss: 0.0232 - val_acc: 0.9930\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0246 - acc: 0.9921 - val_loss: 0.0227 - val_acc: 0.9928\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0245 - acc: 0.9920 - val_loss: 0.0245 - val_acc: 0.9929\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0241 - acc: 0.9926 - val_loss: 0.0223 - val_acc: 0.9939\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0237 - acc: 0.9923 - val_loss: 0.0223 - val_acc: 0.9935\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0229 - acc: 0.9924 - val_loss: 0.0238 - val_acc: 0.9934\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0229 - acc: 0.9926 - val_loss: 0.0234 - val_acc: 0.9931\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0230 - acc: 0.9925 - val_loss: 0.0225 - val_acc: 0.9934\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0231 - acc: 0.9928 - val_loss: 0.0213 - val_acc: 0.9938\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0227 - acc: 0.9925 - val_loss: 0.0233 - val_acc: 0.9934\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0221 - acc: 0.9927 - val_loss: 0.0231 - val_acc: 0.9934\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.0220 - val_acc: 0.9938\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0214 - acc: 0.9931 - val_loss: 0.0227 - val_acc: 0.9932\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0225 - acc: 0.9928 - val_loss: 0.0217 - val_acc: 0.9939\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0202 - acc: 0.9939 - val_loss: 0.0227 - val_acc: 0.9938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f350e3c48d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSdEhsTzt6t8",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model and print score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "84ad5e6f-d256-4d16-fbe1-13f3210c6926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "score = model.evaluate(testX, testy, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0226690605386495, 0.9938]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(testX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "a6c5a1d0-f66f-4684-8ffc-964c22215d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(testy[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.74736100e-15 2.32987514e-08 2.12342783e-08 1.41186973e-07\n",
            "  3.82504908e-07 1.30162621e-14 4.81561402e-24 9.99999285e-01\n",
            "  2.47381282e-12 1.64924273e-07]\n",
            " [1.87051657e-04 5.51770790e-06 9.99786198e-01 1.20462429e-09\n",
            "  6.80183257e-06 2.48225342e-06 1.16120582e-05 1.10153067e-07\n",
            "  2.01053240e-07 8.24227353e-10]\n",
            " [1.51776784e-13 9.99995828e-01 1.05051846e-07 3.35857941e-09\n",
            "  7.44902167e-08 5.51451365e-08 1.31304545e-09 3.55995576e-06\n",
            "  2.62880320e-07 1.14899898e-07]\n",
            " [9.99952435e-01 2.25908346e-14 1.17528856e-07 5.49608492e-09\n",
            "  5.56564601e-07 8.50982929e-08 1.77802267e-05 4.09338868e-10\n",
            "  1.13259722e-08 2.89342861e-05]\n",
            " [2.01791857e-13 1.43728161e-12 1.81763771e-10 3.10897141e-11\n",
            "  9.99981999e-01 1.22243760e-11 1.22574659e-10 1.98394923e-09\n",
            "  4.51824747e-08 1.79301933e-05]\n",
            " [2.08027971e-13 9.99995589e-01 1.54682226e-07 6.06716455e-09\n",
            "  1.29354049e-07 5.03514705e-08 9.63979341e-10 3.55295106e-06\n",
            "  2.43584026e-07 2.96985746e-07]\n",
            " [2.15709256e-11 3.00695831e-07 1.31958757e-06 1.59493474e-09\n",
            "  9.99952793e-01 1.42928528e-07 2.00884601e-10 4.82390533e-06\n",
            "  5.67222105e-06 3.49893126e-05]\n",
            " [1.63720267e-06 5.62487923e-09 1.28666642e-08 1.43612283e-07\n",
            "  4.16220719e-05 6.02412982e-08 8.92076457e-08 3.43235884e-09\n",
            "  2.42820606e-05 9.99932051e-01]\n",
            " [5.88436196e-05 8.77938149e-08 1.28153196e-10 4.36776115e-10\n",
            "  1.96968553e-09 9.40353453e-01 5.92284724e-02 2.34627991e-13\n",
            "  2.84591188e-05 3.30680195e-04]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}