{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Second_Assignment_5_EVA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDeuFNq2CBHO",
        "colab_type": "text"
      },
      "source": [
        "### L2 regulrization , val accuracy 9937 over 40 epochs\n",
        "## Used my own network of Assignmnet 4 ( 8332 parameters with 9948 accuracy)\n",
        "### Observation - accuracy decreased  by 0.02 percent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras\n",
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets and APPLy Image normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-jwdi7iejmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of standardizing a image dataset\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "# image normalization using Image generator\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "eca7f624-a666-4abd-8b86-9624e284f760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "trainy[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "trainy = np_utils.to_categorical(trainy, 10)\n",
        "testy = np_utils.to_categorical(testy, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "a3df34d2-213b-41c1-e382-30fbd49ccb50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "trainy[:10]\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiX_1KmDzMZe",
        "colab_type": "text"
      },
      "source": [
        "### Every layer added L2 regularization\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "24899792-a067-4745-b470-f7bef48b5449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1024
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name ='FirstLayer', input_shape=(28,28,1))) # RF 3x3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu' ,name ='SecondLayer', kernel_regularizer=regularizers.l2(0.01))) # RF 5x5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(14, 3, 3, activation='relu' , name ='ThirdLayer', kernel_regularizer=regularizers.l2(0.01))) # RF 7x7\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # RF 14x14\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, activation='relu'))\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu' , name ='fourthThirdLayer', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu' , name ='FifthLayer', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu' , name ='SixthLayer', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu' , name ='SeventhLayer', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "model.add(Convolution2D(10, 1))#2\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"FirstLayer\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"SecondLayer\", kernel_regularizer=<keras.reg...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(14, (3, 3), activation=\"relu\", name=\"ThirdLayer\", kernel_regularizer=<keras.reg...)`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"fourthThirdLayer\", kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "FirstLayer (Conv2D)          (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "SecondLayer (Conv2D)         (None, 24, 24, 12)        1092      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 24, 24, 12)        48        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 24, 24, 12)        0         \n",
            "_________________________________________________________________\n",
            "ThirdLayer (Conv2D)          (None, 22, 22, 14)        1526      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 22, 22, 14)        56        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 14)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 11, 11, 14)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 9, 10)          1270      \n",
            "_________________________________________________________________\n",
            "fourthThirdLayer (Conv2D)    (None, 7, 7, 12)          1092      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 7, 7, 12)          48        \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 7, 7, 12)          0         \n",
            "_________________________________________________________________\n",
            "FifthLayer (Conv2D)          (None, 5, 5, 10)          1090      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "SixthLayer (Conv2D)          (None, 3, 3, 10)          910       \n",
            "_________________________________________________________________\n",
            "SeventhLayer (Conv2D)        (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 1, 1, 10)          110       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 8,332\n",
            "Trainable params: 8,216\n",
            "Non-trainable params: 116\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"FifthLayer\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"SixthLayer\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"SeventhLayer\", kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UW-SvjCsmSD",
        "colab_type": "code",
        "outputId": "ec151fba-d683-4b4f-a613-d29ed827aa6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2847
        }
      },
      "source": [
        "epochs = 40\n",
        "\n",
        "model.fit_generator(\n",
        "        datagen.flow(trainX, trainy, batch_size =128),\n",
        "        steps_per_epoch= len(trainX)/128, \n",
        "        epochs = epochs , \n",
        "        validation_data=(testX, testy),\n",
        "        callbacks=[LearningRateScheduler(scheduler, verbose=1)],\n",
        "        verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:699: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:707: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "469/468 [==============================] - 9s 20ms/step - loss: 0.6933 - acc: 0.8723 - val_loss: 0.4465 - val_acc: 0.9020\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "469/468 [==============================] - 6s 14ms/step - loss: 0.2122 - acc: 0.9712 - val_loss: 0.1925 - val_acc: 0.9733\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.1701 - acc: 0.9765 - val_loss: 0.1753 - val_acc: 0.9727\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.1449 - acc: 0.9793 - val_loss: 0.1262 - val_acc: 0.9853\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.1333 - acc: 0.9803 - val_loss: 0.1228 - val_acc: 0.9841\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.1208 - acc: 0.9819 - val_loss: 0.1045 - val_acc: 0.9867\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.1127 - acc: 0.9836 - val_loss: 0.1117 - val_acc: 0.9836\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.1061 - acc: 0.9846 - val_loss: 0.1019 - val_acc: 0.9852\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.1013 - acc: 0.9842 - val_loss: 0.0864 - val_acc: 0.9884\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0969 - acc: 0.9849 - val_loss: 0.0832 - val_acc: 0.9883\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0921 - acc: 0.9861 - val_loss: 0.0793 - val_acc: 0.9896\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0873 - acc: 0.9868 - val_loss: 0.0841 - val_acc: 0.9871\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "469/468 [==============================] - 6s 14ms/step - loss: 0.0865 - acc: 0.9862 - val_loss: 0.0747 - val_acc: 0.9912\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0833 - acc: 0.9868 - val_loss: 0.0820 - val_acc: 0.9874\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0792 - acc: 0.9884 - val_loss: 0.0670 - val_acc: 0.9911\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0781 - acc: 0.9880 - val_loss: 0.0664 - val_acc: 0.9904\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0759 - acc: 0.9883 - val_loss: 0.0693 - val_acc: 0.9890\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0747 - acc: 0.9881 - val_loss: 0.0642 - val_acc: 0.9916\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0724 - acc: 0.9886 - val_loss: 0.0596 - val_acc: 0.9925\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0704 - acc: 0.9888 - val_loss: 0.0690 - val_acc: 0.9890\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0688 - acc: 0.9893 - val_loss: 0.0581 - val_acc: 0.9916\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0664 - acc: 0.9899 - val_loss: 0.0655 - val_acc: 0.9897\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0676 - acc: 0.9893 - val_loss: 0.0574 - val_acc: 0.9916\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0663 - acc: 0.9888 - val_loss: 0.0598 - val_acc: 0.9919\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0637 - acc: 0.9897 - val_loss: 0.0574 - val_acc: 0.9917\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0634 - acc: 0.9897 - val_loss: 0.0566 - val_acc: 0.9917\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0616 - acc: 0.9905 - val_loss: 0.0564 - val_acc: 0.9920\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "469/468 [==============================] - 6s 14ms/step - loss: 0.0608 - acc: 0.9906 - val_loss: 0.0540 - val_acc: 0.9923\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0599 - acc: 0.9908 - val_loss: 0.0557 - val_acc: 0.9913\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "469/468 [==============================] - 7s 14ms/step - loss: 0.0593 - acc: 0.9906 - val_loss: 0.0503 - val_acc: 0.9933\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0585 - acc: 0.9906 - val_loss: 0.0548 - val_acc: 0.9919\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "469/468 [==============================] - 6s 14ms/step - loss: 0.0576 - acc: 0.9908 - val_loss: 0.0496 - val_acc: 0.9933\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "469/468 [==============================] - 7s 14ms/step - loss: 0.0579 - acc: 0.9902 - val_loss: 0.0518 - val_acc: 0.9920\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "469/468 [==============================] - 6s 14ms/step - loss: 0.0560 - acc: 0.9912 - val_loss: 0.0504 - val_acc: 0.9928\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "469/468 [==============================] - 6s 14ms/step - loss: 0.0561 - acc: 0.9907 - val_loss: 0.0563 - val_acc: 0.9903\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "469/468 [==============================] - 6s 14ms/step - loss: 0.0557 - acc: 0.9909 - val_loss: 0.0533 - val_acc: 0.9905\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0551 - acc: 0.9911 - val_loss: 0.0477 - val_acc: 0.9937\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "469/468 [==============================] - 6s 14ms/step - loss: 0.0539 - acc: 0.9916 - val_loss: 0.0488 - val_acc: 0.9923\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0538 - acc: 0.9908 - val_loss: 0.0478 - val_acc: 0.9931\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "469/468 [==============================] - 6s 13ms/step - loss: 0.0528 - acc: 0.9913 - val_loss: 0.0493 - val_acc: 0.9923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f71d0045898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSdEhsTzt6t8",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model and print score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "acd71552-45d8-4e7d-c56c-e0be7064c79d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "score = model.evaluate(testX, testy, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.049281451761722564, 0.9923]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(testX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "a6c5a1d0-f66f-4684-8ffc-964c22215d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(testy[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.74736100e-15 2.32987514e-08 2.12342783e-08 1.41186973e-07\n",
            "  3.82504908e-07 1.30162621e-14 4.81561402e-24 9.99999285e-01\n",
            "  2.47381282e-12 1.64924273e-07]\n",
            " [1.87051657e-04 5.51770790e-06 9.99786198e-01 1.20462429e-09\n",
            "  6.80183257e-06 2.48225342e-06 1.16120582e-05 1.10153067e-07\n",
            "  2.01053240e-07 8.24227353e-10]\n",
            " [1.51776784e-13 9.99995828e-01 1.05051846e-07 3.35857941e-09\n",
            "  7.44902167e-08 5.51451365e-08 1.31304545e-09 3.55995576e-06\n",
            "  2.62880320e-07 1.14899898e-07]\n",
            " [9.99952435e-01 2.25908346e-14 1.17528856e-07 5.49608492e-09\n",
            "  5.56564601e-07 8.50982929e-08 1.77802267e-05 4.09338868e-10\n",
            "  1.13259722e-08 2.89342861e-05]\n",
            " [2.01791857e-13 1.43728161e-12 1.81763771e-10 3.10897141e-11\n",
            "  9.99981999e-01 1.22243760e-11 1.22574659e-10 1.98394923e-09\n",
            "  4.51824747e-08 1.79301933e-05]\n",
            " [2.08027971e-13 9.99995589e-01 1.54682226e-07 6.06716455e-09\n",
            "  1.29354049e-07 5.03514705e-08 9.63979341e-10 3.55295106e-06\n",
            "  2.43584026e-07 2.96985746e-07]\n",
            " [2.15709256e-11 3.00695831e-07 1.31958757e-06 1.59493474e-09\n",
            "  9.99952793e-01 1.42928528e-07 2.00884601e-10 4.82390533e-06\n",
            "  5.67222105e-06 3.49893126e-05]\n",
            " [1.63720267e-06 5.62487923e-09 1.28666642e-08 1.43612283e-07\n",
            "  4.16220719e-05 6.02412982e-08 8.92076457e-08 3.43235884e-09\n",
            "  2.42820606e-05 9.99932051e-01]\n",
            " [5.88436196e-05 8.77938149e-08 1.28153196e-10 4.36776115e-10\n",
            "  1.96968553e-09 9.40353453e-01 5.92284724e-02 2.34627991e-13\n",
            "  2.84591188e-05 3.30680195e-04]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}